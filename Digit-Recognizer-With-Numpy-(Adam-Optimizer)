{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":29994,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/hayrilatif/digit-recognizer-with-numpy-adam-optimizer?scriptVersionId=42001753\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Digit Recognizer With Numpy","metadata":{}},{"cell_type":"markdown","source":"In this notebook I will show you how to make a fully connected digit recognizer. We use Adam algorithm for optimize network, mean squared error as a loss function.","metadata":{}},{"cell_type":"markdown","source":"## Preparation","metadata":{}},{"cell_type":"markdown","source":"Firstly, I import required libraries for this notebook. Just **Numpy** for algebra, **Matplotlib** for visualization and **Pandas** for submit predictions as csv.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we must read our data to examine.","metadata":{}},{"cell_type":"code","source":"train_data = np.genfromtxt(\"../input/digit-recognizer/train.csv\",delimiter=',')\ntest_data = np.genfromtxt(\"../input/digit-recognizer/test.csv\",delimiter=',')\nsample_data = np.genfromtxt(\"../input/digit-recognizer/sample_submission.csv\",delimiter=',')","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the shape of **train**, **test** and **sample_submission** data.","metadata":{}},{"cell_type":"code","source":"print(\"train_data= \" , train_data.shape)\nprint(\"test_data= \" , test_data.shape)\nprint(\"sample_data= \" , sample_data.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"train_data= \\n\",train_data,\"\\n\")\nprint(\"test_data= \\n\",test_data,\"\\n\")\nprint(\"sample_data= \\n\",sample_data,\"\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In **train_data** the first column is categories of digits. We must seperate this column to another variable. Except for the **nan** values above.\nIn fact this nan values is column names but **np.genfromtext** method can't read this headers.","metadata":{}},{"cell_type":"code","source":"train_x = train_data[1::,1::]\ntrain_y = train_data[1::,0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, we have a **train_y** variable that will tell us which output neuron to activate.\nWe must encode this arrays, integer to ten-sized arrays according to the integer value.\n\n**Example**\n* 5 >> 0,0,0,0,0,1,0,0,0,0\n* 8 >> 0,0,0,0,0,0,0,1,0,0","metadata":{}},{"cell_type":"code","source":"new_y=[]\nfor i in train_y:\n    a=np.zeros(10)\n    a[int(i)]=1\n    new_y.append(a)\ntrain_y=np.array(new_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, look at the shapes of new variable","metadata":{}},{"cell_type":"code","source":"print(\"train_x= \",train_x.shape)\nprint(\"train_y= \",train_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We should divide our training data into evalu and training.","metadata":{}},{"cell_type":"code","source":"evalu_x=train_x[:4200]\ntrain_x=train_x[4200:]\n\nevalu_y=train_y[:4200]\ntrain_y=train_y[4200:]\n\nprint(\"train_x= \",train_x.shape)\nprint(\"train_y= \",train_y.shape)\nprint(\"eval_x= \",evalu_x.shape)\nprint(\"eval_y= \",evalu_y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**train_x** values are our input values. What we want to do is design a neural network that maps these input values to **train_y** values.","metadata":{}},{"cell_type":"markdown","source":"And, we gotta delete nan rows from both **sample** and **test** data.","metadata":{}},{"cell_type":"code","source":"test_data=test_data[1::]\nsample_data=sample_data[1::]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see our data as image. This will help us to recognize the data.","metadata":{}},{"cell_type":"markdown","source":"To show image, we must reshape our data to 28x28","metadata":{}},{"cell_type":"code","source":"image_to_show=12345 #We have 42000 images, so choose this value between 42000 and -42000 \n\nprint(\"Digit= \",train_y[image_to_show])\nplt.imshow(train_x[image_to_show].reshape(28,28))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"Now, we can look out our real problem, recognize this digits.\nWe can design a Fully Connected Network for this job. Actuaally we never use **FCN**' s to recognize image data.\nBut this data is very small and we can calculate all weights easily.\nIf we have a dataset with big images(Like 256x256) we should use **CNN**(Convolutional Neural Network)' s.","metadata":{}},{"cell_type":"markdown","source":"Our model is small, easy to calculate and enough for this task.\nLet' s look our model' s layers:\n\n1. InputLayer - 784 units - 0 parameter\n2. DenseLayer - 392 units - 307.328 parameters - Sigmoid activation\n3. DenseLayer - 98 units - 38.419 parameters - Sigmoid activation\n4. DenseLayer - 49 units - 4802 parameters - Sigmoid activation\n4. DenseLayer - 10 units - 490 parameters - Sigmoid activation\n\nOur models total parameter(weight) count is **347.224**. This model may seem a little small compared to others but it will be sufficient.\n\nWe use **Adam** algorithm as optimizer.\n\nOur loss function for this model is **Mean Squared Error**","metadata":{}},{"cell_type":"markdown","source":"Now start to make this.","metadata":{}},{"cell_type":"markdown","source":"Firstly, we should define some methods.","metadata":{}},{"cell_type":"code","source":"def mean_squared_error(y, y_hat):\n    return np.mean(np.power(y-y_hat,2))\n\ndef mean_squared_error_der(y,y_hat):\n    return (y-y_hat)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ndef sigmoid_der(x):\n    return sigmoid(x)*(1-sigmoid(x))\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally we can start to make our network.","metadata":{}},{"cell_type":"code","source":"class dense_layer:\n    update_count=0\n    delta=0\n    \n    def __init__(self,input_shape,output_shape,is_last):\n        self.input_shape=input_shape\n        self.output_shape=output_shape\n        self.is_last=is_last\n        self.weights=np.random.random((self.input_shape,self.output_shape))-0.5\n        self.vw=np.zeros((self.input_shape,self.output_shape))\n        self.sw=np.zeros((self.input_shape,self.output_shape))\n        \n    def feed_forward(self,x):\n        self.input_values=x\n        self.output = sigmoid(np.dot(self.input_values,self.weights))\n        return self.output\n    \n    def backprop(self,expected=0,next_layer_gamma=0,next_layer_weights=0):\n        if self.is_last:\n            self.error=mean_squared_error_der(expected,self.output)\n        else:\n            self.error=np.dot(next_layer_gamma,next_layer_weights.T)\n        \n        self.gamma=self.error*sigmoid_der(self.output)\n          \n        self.delta+=np.dot(self.input_values.T,self.gamma)\n    \n    def update_weights(self):\n        self.update_count+=1\n        \n        self.sw=self.sw*beta1+self.delta*(1-beta1)\n        self.vw=self.vw*beta2+self.delta**2*(1-beta2)\n        \n        swc=self.sw/(1-beta1**self.update_count)\n        vwc=self.vw/(1-beta2**self.update_count)\n        \n        self.weights+=swc/(np.power(vwc,1/2)+epsilon)*lr\n        \n        self.delta=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ok, now we can build our model.","metadata":{}},{"cell_type":"code","source":"l1=dense_layer(784,392,False)\nl2=dense_layer(392,98,False)\nl3=dense_layer(98,49,False)\nl4=dense_layer(49,10,True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let' s define our **hyperparameters**. ","metadata":{}},{"cell_type":"code","source":"beta1=0.99\nbeta2=0.999\nepsilon=000000000000.1\nlr=0.001\n\nbatch_size=512\nepochs=30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we define a fit method for run the methods above.","metadata":{}},{"cell_type":"code","source":"def fit(x,y):\n    error_list=[]\n    for ep in range(epochs):\n        seen_points=0\n        error=0\n        \n        for i in range(x.shape[0]):\n            \n            o1=l1.feed_forward(x[i].reshape(1,-1))\n            o2=l2.feed_forward(o1)\n            o3=l3.feed_forward(o2)\n            o4=l4.feed_forward(o3)\n            \n            l4.backprop(y[i])\n            l3.backprop(next_layer_gamma=l4.gamma,next_layer_weights=l4.weights)\n            l2.backprop(next_layer_gamma=l3.gamma,next_layer_weights=l3.weights)\n            l1.backprop(next_layer_gamma=l2.gamma,next_layer_weights=l2.weights)\n            \n            error+=np.mean(l4.error**2)\n            \n            if seen_points%batch_size==0:\n                l4.update_weights()\n                l3.update_weights()\n                l2.update_weights()\n                l1.update_weights()\n                \n                #print(\"Epochs: \",ep+1,\"/\",epochs,\" - Batches: \", i+1,\"/\",x.shape[0])\n            \n            seen_points+=1\n            \n        error=error/x.shape[0]/batch_size\n        \n        error_list.append(error)\n        \n        print(\"Epochs: \",ep+1,\"/\",epochs,\" - Error: \", error)\n        \n    return error_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=fit(train_x/train_x.max(),train_y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let' s look history of our network.","metadata":{}},{"cell_type":"code","source":"print(\"Error\")\nplt.plot(history)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Error down, no problem showing.","metadata":{}},{"cell_type":"markdown","source":"Now, we should write a method that evaluate our network.","metadata":{}},{"cell_type":"code","source":"def prediction(x):\n    o1=l1.feed_forward(x)\n    o2=l2.feed_forward(o1)\n    o3=l3.feed_forward(o2)\n    o4=l4.feed_forward(o3)\n    return o4\n\ndef evaluate(x,y):\n    true=0\n    for i in range(x.shape[0]):\n        if np.argmax(prediction(x[i]))==np.argmax(y[i]):\n            true+=1\n    return true,x.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"true,total=evaluate(evalu_x/evalu_x.max(),evalu_y)\nprint(true/total)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our networks true/total ratio is around **0.9** on unseen data.","metadata":{}},{"cell_type":"code","source":"show_id=300\n\nplt.imshow(train_x[show_id].reshape(28,28))\nprint(\"Prediction= \",np.argmax(prediction(train_x[show_id].reshape(1,-1)/train_x.max())))\nprint(\"Real= \",np.argmax(train_y[show_id]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we can make predictions on test value to submit.","metadata":{}},{"cell_type":"code","source":"submission=pd.DataFrame()\n\npreds=[]\nfor i in range(test_data.shape[0]):\n    preds.append(np.argmax(prediction(test_data[i]/test_data.max())))\n\nsubmission[\"ImageId\"]=np.arange(len(preds))+1\nsubmission[\"Label\"]=preds\n\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Last step, save this **DataFrame** as csv and submit it.","metadata":{}},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks for reading. I will be glad if you point out my mistakes.","metadata":{}}]}