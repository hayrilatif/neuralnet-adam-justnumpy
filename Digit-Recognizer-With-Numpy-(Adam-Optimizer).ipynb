{"cells":[{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://www.kaggle.com/code/hayrilatif/digit-recognizer-with-numpy-adam-optimizer?scriptVersionId=42001753\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["# Digit Recognizer With Numpy"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook I will show you how to implement a fully connected digit recognizer neural network. We will use Adam algorithm to optimize our network and mean squared error as a loss function."]},{"cell_type":"markdown","metadata":{},"source":["## Preparation"]},{"cell_type":"markdown","metadata":{},"source":["Firstly, I imported the required libraries for this notebook. Just **Numpy** for algebra, **Matplotlib** for visualization and **Pandas** for submit predictions as csv."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["Now, we must read our files to examine the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["train_data = np.genfromtxt(\"../input/digit-recognizer/train.csv\",delimiter=',')\n","test_data = np.genfromtxt(\"../input/digit-recognizer/test.csv\",delimiter=',')\n","sample_data = np.genfromtxt(\"../input/digit-recognizer/sample_submission.csv\",delimiter=',')"]},{"cell_type":"markdown","metadata":{},"source":["Let's look at the shape of **train**, **test** and **sample_submission** datas."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"train_data= \" , train_data.shape)\n","print(\"test_data= \" , test_data.shape)\n","print(\"sample_data= \" , sample_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"train_data= \\n\",train_data,\"\\n\")\n","print(\"test_data= \\n\",test_data,\"\\n\")\n","print(\"sample_data= \\n\",sample_data,\"\\n\")"]},{"cell_type":"markdown","metadata":{},"source":["In **train_data** the first column is categories of digits. We must seperate this column to another variable. Except for the **nan** values above.\n","In fact this nan values is column names but **np.genfromtext** method can't read this headers."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_x = train_data[1::,1::]\n","train_y = train_data[1::,0]"]},{"cell_type":"markdown","metadata":{},"source":["Ok, we have a **train_y** variable that will tell us which output neuron should be activated.\n","We must encode this arrays, an integer to size-10 arrays according to the integer value.\n","\n","**Example**\n","* 5 >> 0,0,0,0,0,1,0,0,0,0\n","* 8 >> 0,0,0,0,0,0,0,1,0,0"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["new_y=[]\n","for i in train_y:\n","    a=np.zeros(10)\n","    a[int(i)]=1\n","    new_y.append(a)\n","train_y=np.array(new_y)"]},{"cell_type":"markdown","metadata":{},"source":["Now, we should look at the shapes of the new variables."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"train_x= \",train_x.shape)\n","print(\"train_y= \",train_y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["We should divide our training data as evaluation and training sets."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["evalu_x=train_x[:4200]\n","train_x=train_x[4200:]\n","\n","evalu_y=train_y[:4200]\n","train_y=train_y[4200:]\n","\n","print(\"train_x= \",train_x.shape)\n","print(\"train_y= \",train_y.shape)\n","print(\"eval_x= \",evalu_x.shape)\n","print(\"eval_y= \",evalu_y.shape)"]},{"cell_type":"markdown","metadata":{},"source":["**train_x** values are our input values. What we want to do is design a neural network that maps these input values to **train_y** values."]},{"cell_type":"markdown","metadata":{},"source":["And, we gotta delete nan rows from both **sample** and **test** data."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_data=test_data[1::]\n","sample_data=sample_data[1::]"]},{"cell_type":"markdown","metadata":{},"source":["Let's see our data as image. This will help us to recognize the data."]},{"cell_type":"markdown","metadata":{},"source":["To show image, we must reshape our data to 28x28"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["image_to_show=12345 #We have 42000 images, so choose this value between 42000 and -42000 \n","\n","print(\"Digit= \",train_y[image_to_show])\n","plt.imshow(train_x[image_to_show].reshape(28,28))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can look out our real problem, recognize this digits.\n","We can design a Fully Connected Network for this job. In real world generally we prefer not to use **FCN**' s to classify image data.\n","But in this dataset every sample is very small and we don't need to account training or inference times, we can calculate all the weights easily.\n","If we had a dataset with big images(256x256 or bigger) we would use **CNN**(Convolutional Neural Network)' s or other specialized network architectures."]},{"cell_type":"markdown","metadata":{},"source":["Our model is small, easy to calculate and enough for this task.\n","Let' s look our model' s layers:\n","\n","1. InputLayer - 784 units - 0 parameter\n","2. DenseLayer - 392 units - 307.328 parameters - Sigmoid activation\n","3. DenseLayer - 98 units - 38.419 parameters - Sigmoid activation\n","4. DenseLayer - 49 units - 4802 parameters - Sigmoid activation\n","4. DenseLayer - 10 units - 490 parameters - Sigmoid activation\n","\n","Our models total parameter(weight) count is **347.224**. This model may seem a little small compared to others but it will be sufficient.\n","\n","We use **Adam** algorithm as optimizer.\n","\n","Our loss function for this model is **Mean Squared Error**"]},{"cell_type":"markdown","metadata":{},"source":["Now it's time to build some things up!"]},{"cell_type":"markdown","metadata":{},"source":["First, we should define some methods."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def mean_squared_error(y, y_hat):\n","    return np.mean(np.power(y-y_hat,2))\n","\n","def mean_squared_error_der(y,y_hat):\n","    return (y-y_hat)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def sigmoid(x):\n","    return 1/(1+np.exp(-x))\n","\n","def sigmoid_der(x):\n","    return sigmoid(x)*(1-sigmoid(x))\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Finally we can start to make our network."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class dense_layer:\n","    update_count=0\n","    delta=0\n","    \n","    def __init__(self,input_shape,output_shape,is_last):\n","        self.input_shape=input_shape\n","        self.output_shape=output_shape\n","        self.is_last=is_last\n","        self.weights=np.random.random((self.input_shape,self.output_shape))-0.5\n","        self.vw=np.zeros((self.input_shape,self.output_shape))\n","        self.sw=np.zeros((self.input_shape,self.output_shape))\n","        \n","    def feed_forward(self,x):\n","        self.input_values=x\n","        self.output = sigmoid(np.dot(self.input_values,self.weights))\n","        return self.output\n","    \n","    def backprop(self,expected=0,next_layer_gamma=0,next_layer_weights=0):\n","        if self.is_last:\n","            self.error=mean_squared_error_der(expected,self.output)\n","        else:\n","            self.error=np.dot(next_layer_gamma,next_layer_weights.T)\n","        \n","        self.gamma=self.error*sigmoid_der(self.output)\n","          \n","        self.delta+=np.dot(self.input_values.T,self.gamma)\n","    \n","    def update_weights(self):\n","        self.update_count+=1\n","        \n","        self.sw=self.sw*beta1+self.delta*(1-beta1)\n","        self.vw=self.vw*beta2+self.delta**2*(1-beta2)\n","        \n","        swc=self.sw/(1-beta1**self.update_count)\n","        vwc=self.vw/(1-beta2**self.update_count)\n","        \n","        self.weights+=swc/(np.power(vwc,1/2)+epsilon)*lr\n","        \n","        self.delta=0"]},{"cell_type":"markdown","metadata":{},"source":["Ok, now we can build our model."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["l1=dense_layer(784,392,False)\n","l2=dense_layer(392,98,False)\n","l3=dense_layer(98,49,False)\n","l4=dense_layer(49,10,True)"]},{"cell_type":"markdown","metadata":{},"source":["Let' s define our **hyperparameters**. "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["beta1=0.99\n","beta2=0.999\n","epsilon=000000000000.1\n","lr=0.001\n","\n","batch_size=512\n","epochs=30"]},{"cell_type":"markdown","metadata":{},"source":["Now we define a fit method for run the methods above."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def fit(x,y):\n","    error_list=[]\n","    for ep in range(epochs):\n","        seen_points=0\n","        error=0\n","        \n","        for i in range(x.shape[0]):\n","            \n","            o1=l1.feed_forward(x[i].reshape(1,-1))\n","            o2=l2.feed_forward(o1)\n","            o3=l3.feed_forward(o2)\n","            o4=l4.feed_forward(o3)\n","            \n","            l4.backprop(y[i])\n","            l3.backprop(next_layer_gamma=l4.gamma,next_layer_weights=l4.weights)\n","            l2.backprop(next_layer_gamma=l3.gamma,next_layer_weights=l3.weights)\n","            l1.backprop(next_layer_gamma=l2.gamma,next_layer_weights=l2.weights)\n","            \n","            error+=np.mean(l4.error**2)\n","            \n","            if seen_points%batch_size==0:\n","                l4.update_weights()\n","                l3.update_weights()\n","                l2.update_weights()\n","                l1.update_weights()\n","                \n","                #print(\"Epochs: \",ep+1,\"/\",epochs,\" - Batches: \", i+1,\"/\",x.shape[0])\n","            \n","            seen_points+=1\n","            \n","        error=error/x.shape[0]/batch_size\n","        \n","        error_list.append(error)\n","        \n","        print(\"Epochs: \",ep+1,\"/\",epochs,\" - Error: \", error)\n","        \n","    return error_list"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history=fit(train_x/train_x.max(),train_y)"]},{"cell_type":"markdown","metadata":{},"source":["Let' s look history of our network."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Error\")\n","plt.plot(history)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Error down, no problem showing."]},{"cell_type":"markdown","metadata":{},"source":["Now, we should write a method that evaluate our network."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def prediction(x):\n","    o1=l1.feed_forward(x)\n","    o2=l2.feed_forward(o1)\n","    o3=l3.feed_forward(o2)\n","    o4=l4.feed_forward(o3)\n","    return o4\n","\n","def evaluate(x,y):\n","    true=0\n","    for i in range(x.shape[0]):\n","        if np.argmax(prediction(x[i]))==np.argmax(y[i]):\n","            true+=1\n","    return true,x.shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["true,total=evaluate(evalu_x/evalu_x.max(),evalu_y)\n","print(true/total)"]},{"cell_type":"markdown","metadata":{},"source":["Our networks true/total ratio is around **0.9** on unseen data."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["show_id=300\n","\n","plt.imshow(train_x[show_id].reshape(28,28))\n","print(\"Prediction= \",np.argmax(prediction(train_x[show_id].reshape(1,-1)/train_x.max())))\n","print(\"Real= \",np.argmax(train_y[show_id]))"]},{"cell_type":"markdown","metadata":{},"source":["Now, we can make predictions on test value to submit."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission=pd.DataFrame()\n","\n","preds=[]\n","for i in range(test_data.shape[0]):\n","    preds.append(np.argmax(prediction(test_data[i]/test_data.max())))\n","\n","submission[\"ImageId\"]=np.arange(len(preds))+1\n","submission[\"Label\"]=preds\n","\n","submission"]},{"cell_type":"markdown","metadata":{},"source":["Last step, save this **DataFrame** as csv and submit it."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.to_csv(\"submission.csv\",index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Thanks for reading."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":861823,"sourceId":3004,"sourceType":"competition"}],"dockerImageVersionId":29994,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
